{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\unkno\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\unkno\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\unkno\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:09<00:00, 180394.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    \"train\": DataLoader(train_data, batch_size=100, shuffle=True,num_workers=1),\n",
    "    \"test\": DataLoader(test_data, batch_size=100, shuffle=True,num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1c4de9f3320>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x1c4decca480>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "\n",
    "        self.convl = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.convl(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx *len(data)}/{len(loaders['train'].dataset)} ({100.*batch_idx/len(loaders['train']):.0f}%)]\\t({loss.item():.6f})')\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output,target).item()\n",
    "            pred = output.argmax(dim=1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders['test'].dataset)} ({100. *correct /len(loaders['test'].dataset): .0f}%\\n)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unkno\\AppData\\Local\\Temp\\ipykernel_18888\\224280314.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t(2.303185)\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t(2.292082)\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t(2.204748)\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t(1.969987)\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t(1.883433)\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t(1.839657)\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t(1.799004)\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t(1.686671)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t(1.756750)\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t(1.760636)\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t(1.667254)\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t(1.707098)\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t(1.671816)\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t(1.640796)\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t(1.702589)\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t(1.709079)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t(1.642022)\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t(1.644683)\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t(1.618223)\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t(1.631436)\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t(1.631149)\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t(1.615597)\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t(1.632345)\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t(1.632520)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t(1.625915)\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t(1.558665)\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t(1.623324)\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t(1.625977)\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t(1.650907)\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t(1.591068)\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy 9304/10000 ( 93%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t(1.603024)\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t(1.620204)\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t(1.606339)\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t(1.584896)\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t(1.576656)\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t(1.600027)\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t(1.620312)\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t(1.577381)\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t(1.604873)\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t(1.540768)\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t(1.603164)\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t(1.574979)\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t(1.628152)\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t(1.555401)\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t(1.554034)\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t(1.578090)\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t(1.569083)\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t(1.569088)\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t(1.578038)\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t(1.577684)\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t(1.556510)\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t(1.618262)\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t(1.590493)\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t(1.568085)\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t(1.559261)\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t(1.572622)\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t(1.639705)\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t(1.558451)\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t(1.592544)\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t(1.587417)\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy 9505/10000 ( 95%\n",
      ")\n",
      "Train Epoch: 3 [0/60000 (0%)]\t(1.547372)\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t(1.550857)\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t(1.571805)\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t(1.545423)\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t(1.544082)\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t(1.602793)\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t(1.607473)\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t(1.560239)\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t(1.598802)\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t(1.528469)\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t(1.586587)\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t(1.554455)\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t(1.547230)\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t(1.575514)\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t(1.529358)\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t(1.540447)\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t(1.568681)\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t(1.558756)\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t(1.599659)\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t(1.573996)\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t(1.542893)\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t(1.579528)\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t(1.597609)\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t(1.551720)\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t(1.559177)\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t(1.539187)\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t(1.587914)\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t(1.518292)\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t(1.620880)\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t(1.580482)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9581/10000 ( 96%\n",
      ")\n",
      "Train Epoch: 4 [0/60000 (0%)]\t(1.516202)\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t(1.600405)\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t(1.595548)\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t(1.592196)\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t(1.531702)\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t(1.516716)\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t(1.552262)\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t(1.551308)\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t(1.551836)\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t(1.567425)\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t(1.551948)\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t(1.554491)\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t(1.535680)\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t(1.559366)\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t(1.579339)\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t(1.547213)\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t(1.518928)\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t(1.542722)\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t(1.539277)\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t(1.558372)\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t(1.527934)\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t(1.589297)\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t(1.560714)\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t(1.545659)\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t(1.501346)\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t(1.617407)\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t(1.549727)\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t(1.572318)\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t(1.600440)\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t(1.568910)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9621/10000 ( 96%\n",
      ")\n",
      "Train Epoch: 5 [0/60000 (0%)]\t(1.508245)\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t(1.516967)\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t(1.521879)\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t(1.571438)\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t(1.551551)\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t(1.616891)\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t(1.515129)\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t(1.531691)\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t(1.602412)\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t(1.535002)\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t(1.526897)\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t(1.528418)\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t(1.507286)\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t(1.561257)\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t(1.533183)\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t(1.543153)\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t(1.543399)\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t(1.552868)\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t(1.578303)\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t(1.511261)\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t(1.581060)\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t(1.509045)\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t(1.562943)\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t(1.562516)\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t(1.511196)\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t(1.560002)\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t(1.571730)\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t(1.519936)\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t(1.566812)\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t(1.539487)\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9650/10000 ( 96%\n",
      ")\n",
      "Train Epoch: 6 [0/60000 (0%)]\t(1.545645)\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t(1.541011)\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t(1.568151)\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t(1.539501)\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t(1.589087)\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t(1.543166)\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t(1.585819)\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t(1.559875)\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t(1.491862)\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t(1.525918)\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t(1.538658)\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t(1.542616)\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t(1.544633)\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t(1.543545)\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t(1.538524)\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t(1.565458)\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t(1.535812)\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t(1.523991)\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t(1.563691)\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t(1.497663)\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t(1.554774)\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t(1.540318)\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t(1.566970)\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t(1.515586)\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t(1.549325)\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t(1.550880)\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t(1.521264)\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t(1.537132)\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t(1.518665)\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t(1.490311)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9675/10000 ( 97%\n",
      ")\n",
      "Train Epoch: 7 [0/60000 (0%)]\t(1.532166)\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t(1.545720)\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t(1.529321)\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t(1.511111)\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t(1.537477)\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t(1.517831)\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t(1.487369)\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t(1.519993)\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t(1.585903)\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t(1.519777)\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t(1.547812)\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t(1.494147)\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t(1.519920)\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t(1.521820)\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t(1.600678)\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t(1.511892)\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t(1.539977)\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t(1.578917)\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t(1.577828)\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t(1.498932)\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t(1.541656)\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t(1.519611)\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t(1.588841)\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t(1.577575)\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t(1.590097)\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t(1.550487)\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t(1.507252)\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t(1.515667)\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t(1.559494)\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t(1.521428)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9698/10000 ( 97%\n",
      ")\n",
      "Train Epoch: 8 [0/60000 (0%)]\t(1.537429)\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t(1.527530)\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t(1.525109)\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t(1.545456)\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t(1.556708)\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t(1.538036)\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t(1.529962)\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t(1.564098)\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t(1.475274)\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t(1.539594)\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t(1.515998)\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t(1.548674)\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t(1.535508)\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t(1.552136)\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t(1.537694)\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t(1.540764)\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t(1.512385)\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t(1.530114)\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t(1.552303)\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t(1.545354)\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t(1.556822)\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t(1.533335)\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t(1.521262)\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t(1.546437)\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t(1.519759)\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t(1.512723)\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t(1.544728)\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t(1.559372)\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t(1.571204)\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t(1.541140)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9694/10000 ( 97%\n",
      ")\n",
      "Train Epoch: 9 [0/60000 (0%)]\t(1.543986)\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t(1.510096)\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t(1.499741)\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t(1.511075)\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t(1.532168)\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t(1.534423)\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t(1.516773)\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t(1.548209)\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t(1.569180)\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t(1.529768)\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t(1.537943)\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t(1.489285)\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t(1.512943)\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t(1.569924)\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t(1.539999)\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t(1.561085)\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t(1.581619)\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t(1.512494)\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t(1.594838)\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t(1.590493)\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t(1.519406)\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t(1.566744)\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t(1.518405)\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t(1.549061)\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t(1.488308)\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t(1.522447)\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t(1.532048)\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t(1.522208)\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t(1.559168)\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t(1.509369)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9738/10000 ( 97%\n",
      ")\n",
      "Train Epoch: 10 [0/60000 (0%)]\t(1.483904)\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t(1.549641)\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t(1.494388)\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t(1.499056)\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t(1.593958)\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t(1.523873)\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t(1.553913)\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t(1.512868)\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t(1.524120)\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t(1.517618)\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t(1.533966)\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t(1.546709)\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t(1.615038)\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t(1.519337)\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t(1.502984)\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t(1.509271)\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t(1.559612)\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t(1.533069)\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t(1.482435)\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t(1.531123)\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t(1.528736)\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t(1.534650)\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t(1.529484)\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t(1.547446)\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t(1.520156)\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t(1.493725)\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t(1.498048)\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t(1.590389)\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t(1.554757)\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t(1.521667)\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9740/10000 ( 97%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#for training\n",
    "for epoch in range(1,11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\unkno\\AppData\\Local\\Temp\\ipykernel_18888\\224280314.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data,target  = test_data[7]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim = True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
